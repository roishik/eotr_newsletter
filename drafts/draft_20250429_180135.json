{
    "overall_prompt": "What are you doing?:\nYou are writing a section inside an internal Mobileye newsletter on autonomous cars, the car industry, and AI news. Only write about the relevant content of this section - This text will be a part of the big newsletter (no need for welcome notes). Avoid AI chatbot introductions, such as 'here is the response to your request'.\nWriting style:\nWrite in a dynamic, conversational, and friendly tone, as if speaking directly to the reader. Keep the language approachable but insightful, mixing professional analysis with a sense of curiosity and enthusiasm. Use simple, clear sentences, but don't shy away from technical terms when necessary\u2014just explain them naturally and without overcomplication. Add thoughtful commentary that connects news or updates to broader implications, offering personal insights or lessons. Maintain an optimistic and forward-thinking voice, encouraging readers to reflect and engage while keeping the overall mood warm and encouraging. Don't be too optimistic and avoid making announcements that are bigger than the actual news.\nLength:\nKeep the response concise and focused on the key points.\nWhat to write about?\nOffer a new lens on the news, providing a fresh perspective or a unique angle that doubts the status quo or offers a new way of thinking.",
    "windshield_urls": "https://www.theverge.com/cars/642706/car-tariff-trump-price-increase-loan-ford-gm-tesla",
    "windshield_notes": "",
    "windshield_prompt": "Summarize the articles in 2\u20133 concise paragraphs. Please be succinct and avoid unnecessary details. Write in first-person singular.  ",
    "num_rearview": 3,
    "dashboard_urls": "",
    "dashboard_notes": "The AI Race Has Gotten Crowded\u2014and China Is Closing In on the US\nNew research from Stanford suggests artificial intelligence isn\u2019t ruled by just OpenAI and Google, as competition increases across the US, China, and France.\nPlay/Pause Button\nAnimation: Jacqui VanLiew; Getty Images\n\nThe year that ChatGPT went viral, only two US companies\u2014OpenAI and Google\u2014could boast truly cutting-edge artificial intelligence. Three years on, AI is no longer a two-horse race, nor is it purely an American one. A new report published today by Stanford University\u2019s Institute for Human-Centered AI (HAI) highlights just how crowded the field has become.\nThe institute\u2019s 2025 AI index, which collates data and trends on the state of the AI industry, paints a picture of an increasingly competitive, global, and unrestrained race towards artificial general intelligence\u2014AI that surpasses human abilities.\nOpenAI and Google are still neck and neck in the race to build bleeding-edge AI, the report shows. But several other companies are closing in. In the US, the fiercest competition comes from Meta\u2019s open weight Llama models; Anthropic, a company founded by former OpenAI employees; and Elon Musk\u2019s xAI.\nFeatured Video\n \nMost strikingly, according to a widely used benchmark called LMSYS, the latest model from China\u2019s DeepSeek, R1, ranks closest to the top-performing models built by the two leading American AI companies.\n\u201cIt creates an exciting space. It\u2019s good that these models are not all developed by five guys in Silicon Valley,\u201d says Vanessa Parli, director of research at HAI.\n\u201cChinese models are catching up as far as performance to the US models,\u201d Parli adds, \u201cBut across the globe, there are new players emerging in the space.\u201d\nImage may contain Chart and Line Chart\nCourtesy of Stanford HAI\nThe arrival of DeepSeek-R1 in January sent shock waves through the US tech industry and stock market. The company claimed to have built its model using a fraction of the compute used by US rivals. DeepSeek\u2019s debut was also a surprise because the US government has repeatedly sought to limit China\u2019s access to the computer chips needed to build the most advanced AI.\nMost Popular\nWhat Is the Meta AI Button in WhatsApp, and How Do I Remove It?\nHow To and Advice\nWhat Is the Meta AI Button in WhatsApp, and How Do I Remove It?\nBy Diego Barbera\nThe Proud Boys and Militias Come to Tesla\u2019s Defense\nPolitics\nThe Proud Boys and Militias Come to Tesla\u2019s Defense\nBy David Gilbert\nDOGE Is Planning a Hackathon at the IRS. It Wants Easier Access to Taxpayer Data\nPolitics\nDOGE Is Planning a Hackathon at the IRS. It Wants Easier Access to Taxpayer Data\nBy Makena Kelly\nInside DOGE\u2019s AI Push at the Department of Veterans Affairs\nPolitics\nInside DOGE\u2019s AI Push at the Department of Veterans Affairs\nBy Vittoria Elliott\nStanford\u2019s report shows Chinese AI is on the rise overall, with models from Chinese companies scoring similar to their US counterparts on the LMSYS benchmark. It notes that China publishes more AI papers and files more AI-related patents than the US, although it does not assess the quality of either. The US, in contrast, produces more notable AI models: 40 compared to the 15 frontier models produced in China and the three produced in Europe. The report also notes that powerful models have recently emerged in the Middle East, Latin America, and Southeast Asia, as the technology becomes more global.\nImage may contain Chart and Line Chart\nCourtesy of Stanford HAI\nThe research shows that several of the best AI models are now \u201copen weight,\u201d meaning they can be downloaded and modified for free. Meta has been at the center of the trend with its Llama model, first released in February 2023. The company released its latest version, Llama 4, over the weekend. Both DeepSeek and Mistral, a French company, now offer advanced open weight models, too. In March, OpenAI announced that it also plans to release an open source model\u2014its first since GPT-2\u2014this summer. In 2024, the gap between open and closed models narrowed from eight percent to 1.7 percent, the study shows. That said, the majority of advanced models\u201460.7 percent\u2014are still closed.\nStanford\u2019s report notes the AI industry has seen a steady improvement in efficiency, with hardware becoming 40 percent more efficient in the past year. This has brought the cost of querying AI models down and also made it possible to run relatively capable models on personal devices.\nRising efficiency has prompted speculation that the largest AI models could require fewer GPUs for training, although most AI builders say they need more computing power, not less. The study shows that the latest AI models are built using tens of trillions of tokens\u2014components representing parts of data such as words in a sentence\u2014and tens of billions of petaflops of computation. However, it cites research suggesting that the supply of internet training data will be exhausted by between 2026 and 2032, hastening the adoption of so-called synthetic, or AI-generated, data.\nThe report offers a sweeping picture of AI\u2019s broader impact. It shows that demand for workers with machine learning skills has spiked, and cites surveys showing that a growing proportion of workers expect the technology to change their jobs. Private investment reached a record $150.8 billion in 2024, the report shows. Governments around the world also committed billions to AI that same year. Since 2022, AI-related legislation has doubled in the US.\nParli notes that although companies have become more secretive about how they develop frontier AI models, academic research is flourishing\u2014and improving in quality.\nThe report also points to problems arising from widespread AI adoption. It notes that incidents involving AI models misbehaving or being misused have increased in the past year, as has research aimed at making these models safer and more reliable.\nAs for reaching the much ballyhooed goal of AGI, the report highlights how some AI models already surpass human abilities on benchmarks that test specific skills, including image classification, language comprehension, and mathematical reasoning. This is partly because models are designed and optimized to excel at these barometers, but it shines a spotlight on how swiftly the technology has advanced in recent years.",
    "dashboard_prompt": "Write 3 parts:\n- What's New: Describe key trends or insights concisely.\n- Why It Matters: Explain the impact on our market and potentially israel.\n- What I Think: Share a brief personal opinion.",
    "nextlane_urls": "https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWY4G099kk0rW7Vs7db2_RgSvW2C4PM95vMRRsN7-7xzl3qgyTW7Y8-PT6lZ3l-W2vQMgH8kXGc2W5Z4GV31XT26fW1LwS_78Y9nG_W4b78LT7QnL2gW6KR3c17PQZFKW4v_Dwh94VtyDW2pPZpH4PDfdZW9fgDJm1KmKkKW8jwQ-V5LYyFZW36YDxF2nZCfNW2mGdR85CX3HgVbcTxN1Bf8y_W7ST62r5lDDlKW70jhDv7WPTnHV_Cv_18fCpbQW6LCdtv1FkLdMN31CTjh55vcjW1m1TYg4Bc1NbW606SNz5Yx8TDW52dxg551HHnZW1Lt14W9d3wlsW2LjP-N2c5Wg9N6k7Z6LblCFZV3hqmr8R0ZPgW2dHbH12yqsn8N4b8_8MRkWbTf7DCVZY04;https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWY4G099kk0rW7Vs7db2_RgSvW2C4PM95vMRRsN7-7xxT5nR32W50kH_H6lZ3mTN8_sZgw-83cTW3D3_by1ZDZY5W80BgHx6yd93KN2psH57DtLMcW6cjTwq7P-G_vF5sGgs7GtshW6373mW6PSH-nW6lk2xJ7f1k7BN17QbXtfZLlYW3JvXKj8G8WdXN7cnMpWlLLc4V3Z0VS3TsGmTW7Y9Mkm8xYMvTW66LJTK9lTJP4W31nVrQ2h8jvSW7F6CV63vcB1sW1gLRCy4lNTnsW8Yhvd878DtlzVXjvHQ5y84LMW7RrW3j8nHxC_W3Rr0TJ4p6Sq1W7xSf0K3VhlYVW7MQYW69jVvfXW2PN-lW89fmZ1Vt5YsH6z5QwbW6CXc6Z6cskzxW36bfbm1WJkjJW7hRHzB3X5sLGVfZXmP1yXQDvVVzLv_13c5y7W88MXg317D8S0W8Ndzvf1fvmmMf41R01v04;",
    "nextlane_notes": "Hugging Face Rolls Out Open Robot\nHugging Face has made a name by providing open AI models. Now it\u2019s providing an open robot.\n\nWhat\u2019s new: Hugging Face acquired the French company Pollen Robotics for an undisclosed price. It plans to offer Pollen\u2019s Reachy 2, a robot that runs on code that\u2019s freely available under an Apache 2.0 license, for $70,000.\n\nHow it works: Reachy 2 has two arms, gripper hands, and a wheeled base (optional). It\u2019s designed primarily for education and research in human-robot interaction in real-world settings.\n\nReachy 2 is programmable in Python and runs models from Hugging Face\u2019s LeRobot library.\nIt runs control software locally on a SolidRun Bedrock V3000 (a PC based on an AMD Ryzen Embedded V3000 processor) and processes AI in the cloud or on a local server.\nThe robot responds to VR controllers including Meta Quest 2 and 3 as well as Pollen\u2019s VR app.\nIts head senses the visual environment using a pair of cameras equipped with global shutters to capture fast-changing events and measures distances via an optical sensor. Its antennas are outfitted with microphones to capture sounds, and its torso senses distances using a depth camera. The base includes a lidar sensor to aid navigation.\nThe body features 3D joints in the neck and wrists and 2D joints in the shoulders and elbows. Each arm can lift objects of up to 3 kilograms.\nA rechargeable, 24 volt battery provides around 10 hours of battery life.\nBehind the news: Last year, Remi Cadene, who worked on Tesla\u2019s Optimus, joined Hugging Face to lead robotics projects. In May, he and his team rolled out the LeRobot open source robotics code library, which provides pretrained models, datasets, and simulators for reinforcement learning and imitation learning. In November, Nvidia announced a collaboration with Hugging Face to accelerate LeRobot\u2019s data collection, training, and verification.\n\nWhy it matters: Hugging Face\u2019s acquisition of Pollen reflects an industry-wide investment in robots, notably humanoid robots, whose prices have been falling. Nvidia CEO Jensen Huang has called AI-enabled robotics a \u201cmulti-trillion dollar\u201d opportunity. \n\nWe\u2019re thinking: AI-enabled robots are marching slowly toward what we hope will be breakthrough applications. Open-source systems are an important part of the trend!",
    "nextlane_prompt": "Summarize competitor/academic news in 2\u20133 concise paragraphs, highlighting its implications for Mobileye. Keep it brief and to the point.",
    "generated_sections": {
        "Windshield View": "The recent imposition of 25 percent tariffs on imported vehicles by President Trump is causing significant turbulence in the auto industry, and it's not just a ripple\u2014it's a tidal wave. With car prices already historically high and many buyers struggling with loans, these tariffs are expected to hike prices further, potentially adding $5,000 to $10,000 or even more to the cost of a new vehicle. The notion of simply \"buying American\" isn't a straightforward solution either, as even domestic cars rely heavily on a global supply chain. This policy is pushing the industry into disarray, with the price of cars, especially at the lower end, set to soar.\n\nThe broader implications are particularly concerning for consumers. The average transaction price for a new car is already a hefty $48,118, and with tariffs kicking in, affordability is becoming an even more pressing issue. The market is seeing a dwindling number of vehicles priced under $30,000, and tariffs threaten to shrink this segment further. Moreover, with many consumers already stretching their finances with extended loan terms and negative equity in their vehicles, the increased costs could push car ownership further out of reach for many.\n\nIn response, some automakers are trying to cushion the blow. Ford is offering temporary discounts, and Hyundai plans a significant investment in the U.S. Meanwhile, the White House is considering tax breaks and deregulation as potential relief measures. However, the uncertainty looms, and consumer anxiety is palpable, with some rushing to buy cars before prices climb further. It's a complex situation with no easy answers, underscoring the interconnectedness of global trade and domestic policy and the need for strategic, thoughtful approaches to navigate these choppy waters.",
        "Rearview Mirror 1": "**Kawasaki Corleo Robo-Explorer: Off-Road Revolution with Legs**  \nThe Kawasaki Corleo Robo-Explorer introduces a groundbreaking four-legged design for off-road vehicles, challenging traditional wheeled models and hinting at a future where mobility platforms might resemble agile robotic dogs.",
        "Rearview Mirror 2": "**Nimrod Nehushtan's Podcast Insights: The Future of Driver Assistance**\n\nIn the latest \"Ride AI\" podcast, Mobileye's EVP of Business Development, Nimrod Nehushtan, delved into the transformative impact of bringing Level 2+ driving systems to mid-range vehicles, highlighting a pivotal shift towards democratizing advanced driver-assist technologies. Nimrod emphasized the industry's evolution from luxury-exclusive features to widespread accessibility, underscoring the importance of regulatory standards and innovative mapping technologies in paving the way for a future where intelligent driving systems enhance safety and convenience for all. As the conversation unfolded, it was clear that while the journey to fully autonomous driving remains complex, the path forward is increasingly tangible and promising.",
        "Rearview Mirror 3": "**A Twist of Romance and Deceit: The Bizarre Scandal Shaking Tel Aviv\u2019s Startup Scene**  \nPromai's lawsuit reveals an incredible tale of deceit, with its former CEO allegedly using ChatGPT to forge contracts with Boeing, all while weaving a personal web of lies, posing as an Air Force officer. This astonishing saga highlights the challenges startups face in balancing trust and innovation within their leadership circles.",
        "Dashboard Data": "**What's New:**\nThe AI landscape is no longer dominated solely by OpenAI and Google. According to a new report from Stanford University\u2019s Institute for Human-Centered AI, we're witnessing a global surge in AI innovation. Notably, China's DeepSeek has made headlines with its high-performing model, R1, which challenges U.S. dominance. There\u2019s also a notable rise in \"open weight\" models, with companies like Meta, DeepSeek, and Mistral offering models that are free to download and modify. AI efficiency is improving, making it more accessible and affordable to run sophisticated models on personal devices. However, there\u2019s a looming concern about the depletion of internet training data, which might accelerate the use of synthetic data.\n\n**Why It Matters:**\nFor the global market, particularly for tech hubs like Israel, this diversification in AI development could mean more collaboration opportunities and a competitive edge for local startups eager to integrate or innovate alongside these new players. As AI becomes more distributed, Israel, with its thriving tech ecosystem, could position itself as a key contributor in this global AI race. The shift towards open models could democratize AI development, enabling smaller firms to experiment and innovate without prohibitive costs. This increased competition and efficiency could drive down costs and spur more rapid advancements, ultimately benefiting consumers and industries alike.\n\n**What I Think:**\nThe expanding AI landscape is exciting and a bit like a roller coaster ride\u2014full of unexpected turns and thrills. The entry of China's DeepSeek and others signals a shift towards a more balanced global AI ecosystem. While it's crucial to keep an eye on the ethical implications and ensure robust safety measures, this competitive diversity could lead to more innovative solutions and breakthroughs. For Israel, this presents a golden opportunity to leverage its strong tech scene and collaborate on a global stage, potentially leading to groundbreaking advancements that could shape the future of AI. The challenge will be in navigating data limitations and ensuring responsible AI growth, but the potential rewards are immense.",
        "The Next Lane": "Hugging Face's recent acquisition of Pollen Robotics marks an exciting chapter in the open-source robotics arena. By introducing the Reachy 2, Hugging Face is not just expanding its portfolio but is also reinforcing the importance of accessibility and collaboration in the robotics field. This robot, equipped with advanced features such as dual arms, a wheeled base, and the ability to process AI in both local and cloud environments, is targeted at education and research in human-robot interaction. This move underscores the shifting focus towards more affordable and adaptable humanoid robots that can be programmed using widely accessible languages like Python.\n\nFor Mobileye, this development in the robotics industry is a key signal of the growing trend towards open-source platforms. As autonomous vehicle technology continues to evolve, the integration of open-source models could offer new pathways to enhance flexibility and innovation. The potential for collaboration and shared learning could accelerate advancements in AI and robotics, driving down costs and broadening application possibilities. It's an invitation to re-evaluate how open platforms might be leveraged to push the boundaries of autonomous technology.\n\nMoreover, with AI-enabled robotics being lauded as a \"multi-trillion dollar\" opportunity, the implications for the automotive industry cannot be overstated. Embracing open-source projects like Hugging Face's could be the catalyst for breakthroughs in autonomous systems, leading to smarter, more adaptive, and ultimately more human-centric solutions. This encourages us to think creatively about how we might harness these trends to advance our own innovations and maintain a competitive edge in the fast-evolving landscape of autonomous technologies."
    },
    "edited_sections": {},
    "selected_provider": "OpenAI",
    "selected_model": "gpt-4o",
    "language": "English",
    "theme": "Light",
    "rearview_urls_1": "https://canadamotoguide.com/2025/04/09/kawasaki-corleo-robo-explorer-an-off-road-vehicle-with-legs/",
    "rearview_notes_1": "Will our next platform be a 4-legs dog?",
    "rearview_prompt_1": "Provide a brief headline (bolded text, not an actual headline) and a one-sentence summary. Keep the response extremely concise\u2014no more than 2 sentences total.",
    "rearview_urls_2": "",
    "rearview_notes_2": "Here is a text from a podcast our EVP of business development Nimrod Nehushtan did (\"Ride AI\"). The transcript include the text from the interviewer and Nimrod:\n Hello and welcome to the Rite AI podcast. I'm Ed Neeter-Meier. I'm also very excited to be chatting today with someone from one of the companies that is one of the partners for the Rite AI event as well as one of the of the huge names in the driving automation technology space. Nimra Nushan is the executive vice president for strategy and business development at Mobileye. Nimra, thank you so much for being here today. Thank you very much Ed. Pleasure being here. So I want to start with some of the big news that is just broken shortly before we recorded this. Mobileye announced a big deal with Vallejo and Volkswagen. This is to provide level two plus systems for the MQB electric vehicle family. So tell us about what this deal says about the current state of the ADAS market. It seems like to me that sort of L2 plus something that was pretty cutting out a couple years ago is starting to really become something that is almost everywhere in the auto industry now. Yeah, that's a good point to start with. So generally this program is about introducing the next generation or driver assist features to a much broader segment of vehicles. And whereas maybe until today it was mostly referred to like level two plus or level three was mostly referred to premium cars maybe very specific car models to begin with. Now it seems that there is a bigger understanding that the future of cars will be determined by intelligent driving. And that is true for mid-trims and low-trim cars as well. And the significance of this announcement is that it introduces level two plus which means hands-free driving in certain primary roads to pretty much $20,000 cars, $30,000 cars which will make it pervasive and available for pretty much everyone. And being adopted by Volkswagen Group who obviously make dozens of different models with multiple brands in all markets practically is a very strong push to this. Yeah, it's funny there are two pieces going on all the time. There's the innovation pushing forward at the cutting edge but then what the auto industry always does so well is taking things that are at the cutting edge and then making them available to everyone and really driving down that cost so that you get those benefits at massive scale. So that of course leads us to what's the next step? So if this is if L2 plus is becoming sort of a table stakes almost, where is that next? So where are you pushing forward in terms of the technology in terms of the products that you're putting out in the market? Yeah, so I think mobile has been very very consistent in being one of the industry's powerhouses in launching new technologies in large scale in volumes working with dozens of OEMs over the years. And in recent years we're kind of working very hard on our next generation of products. And that spans from entry level driver assist features which is basically a front camera-based system that provides alerts and warnings and helps the driver prevent the injuries events. Moving from that entry segment to the mid-stream which is what we have just been talking about which is hands-free in primary roads but still a very cost-efficient system that gives you not just this hands-free comfort feature but also gives you much better safety features for the future regulation. So one of the driving forces behind the emergence of advanced ADAS is regulatory bodies are also trying to push the envelope of what will be required to have the highest safety score in the future. And it will require more sensor potentially, it will require more sophisticated compute and more sophisticated AI. And this is kind of the next standard we believe. Yeah, I'm sorry not to catch you off but it's funny I've been doing some history on even the Tesla autopilot and the first reason to put sensors in these vehicles and some of the most famous examples was to meet some of these regulatory standards which I think as consumers a lot of people don't understand. Tell us a little bit where are those standards being pushed forward the most just so we understand in the global sort of picture. Yeah, so I think traditionally Europe has been leading when it comes to safety standards and safety regulation and automotive and euro and cap is a very well-renowned body that provides kind of incentivizes OEMs to invest in safety by given them safety scores and that can be used as a kind of a marketing element for OEMs that want to brand themselves as a safe car and the safest car. So every couple of years euro and cap publishes a new set of features or a set of use cases that in order to get the highest rating you need to comply with and that continuously pushes the bar of what is considered the best in class and in if you look at 2028 or 2728 onwards it's really a significant leap in what will be required. And we believe that this is another driving force for broader adoption of advanced features, level 2 plus, level 2 plus plus and combining with the fact that with days technologies we can make this in a very cost efficient way can really make this a very compelling argument because you know regulatory bodies do not want to create a standard that is impossible to comply with unless you make the car twice as much in price. So it's always a balance between like the upside of bitter safety versus what could it mean on consumers that will now need to spend more. Right. Right. And then when you're putting in hardware, that's where a lot of the cost of this comes from and you have to put it into meet a regulatory standard but then it unlocks other convenience features or things like that then you can take something that might just be sort of a cost to meet a compliance standard and actually offer them features that are more appeal. Right. It's not just meeting that regulatory standard. Yeah. So maybe if I can take a step backwards and kind of recap our portfolio and the different products from the lens of a consumer, you know, what will it mean on drivers? Not just regulatory bodies or not just systems and engineering aspects but for consumers for the everyday user, what would it mean on the experiences that I can have in a car? So again, starting from entry ADAS which is basically providing alerts, warnings to prevent dangerous things. This is what's the standard today like emergency braking, collision warnings and so on. From that point, there is like this surround ADAS which is basically as a driver, you're still driving most of the time, you're so responsible and yet in certain primary roads, you can take your hands off. So you can think of it as another upgrade for cruise control, which is a very like convenient feature to use but it still has limitations today and this is like taking it a few steps forward which means the system can steer the car and it can also adapt velocity in a much more sophisticated way. So as a driver, you don't need to intervene and help it, you know, very frequently, if at all. And then the next product is what we call supervision is a point to point, hands off driving everywhere. So basically as a driver, you enter the car, you're select your destination and the car takes you from point A to point B autonomously but still you need to be eyes on. Okay, this is like being a pilot in a commercial plane today, roughly speaking, you still need to supervise what's going on but again, the stress and load of driving is much lower on you. From that point, we have chauffeur which is kind of the crown jewel of our portfolio and has the highest promise I think for consumers because it's the first scalable product that offers time back to drivers. And this is for eyes off driving. The first first launch will be for highways and intercity roads. So again, imagine the user experience or enter the car, you select the destination and then once you enter the highway, you can take your eyes off it, you can mind your own business, you can do other things. That is a dramatic improvement and change in value proposition to consumers. And our roadmap is to launch this in two years, roughly speaking. And the leading program is without it, it will be offered in the US and Europe. So it's a very big milestone for us. And then finally, our final product is mobile iDrive which is designed for robot axes and kind of enabling mobility as a service. It's designed for fleets. So you can deploy this on a fleet of cars and then operate a robot axis service in a certain city, certain area. And this is kind of a very, very broad spectrum of products but we are, this is in the core mission of the company today. Yeah, no. And I love as someone who's spent a little time on the public education side of this. I love the, there's a simplicity to the hands off, eyes off way you describe it. You're not talking about levels of automation. You're not having people look up the J-30-16 standard for that, you know, I find that very refreshing because I think, you know, I think you need to put it in those terms of what a consumer is actually going to experience for them to understand it because they don't know what the numbers mean, right? Yeah. And I think that if you think about how consumers have been experiencing transportation in the past two decades, it's mostly through safety, comfort, time, and cost. And in these four axes, in safety, you can, you can say that we have made very good progress. You know, there's today a much better answer for safety incidences in cars and cars are safer today, you know, statistically you can prove it. But still, where it's far from a solved problem, you know, they're still more to do. Comfort, we've made maybe moderate progress. Still, you have features like cruise control that can be activated and some people use it, some nuts, but still practically the experience that you have in a car is practically the same as it has been two decades ago. The cost is pretty much the same, so it's not that new technologies have inflated significantly the price of cars, but in time, we have made if anything negative progress, I think that people today, you can argue, spend more time wasting more time in a car than they have been. So I think this is, this is a good way to understand where is the biggest opportunity, you know, the next two decades is, you know, getting from, you know, time waste to an efficient utilization of time and getting closer to completely diminishing or eliminating car accidents. That is kind of our future and our, you know, vision for the future. And we definitely believe that within the next few years, there will be a step function change in these parameters through our product launches. Yeah, so I want to dive into this because I think the the eyes off sort of vision, right? That has been, you know, we've had L2 L2 Plus for a while, there's sort of L2 Plus Plus, but and there have been companies who, OEMs, who've said, you know, we're going to bring, I quote unquote L3, right, an eyes off system to market, and they've had to kind of back off on this. This has clearly been a very challenging line to cross this from the hands off, right? There's a lot of different kind of ways and implementations. Getting to eyes off is clearly challenging. Talk to me a little bit about what makes that, that taking that step so challenging. Yeah, so I think that there is a, as you very well said, nobody argues about the potential value of having eyes off products. So the fact that we still don't have these products available in the market in a broad sense is not because it's not attracted. It's mostly because it's complicated. And the complexity comes from a very, very challenging balance between safety and usefulness that in order to make a useful product, you need to have a broad enough range of availability of the car. And if you want to support this broad range, while maintaining a very strict safety standard, then it creates a very complicated technological engineering problem. And you don't want to be optimizing just for one. You don't want to have a very safe system that is not useful, because if it means that it will only be available, you know, an hour a year, because it needs a perfect set of circumstances and a perfect set of environmental conditions or, you know, traffic density conditions, what not, then, you know, nobody is interested in this. And, and of course, you don't want to have a system that statistically can fail systematically because of certain deficiencies, because in the first instance, it will happen, the social acceptance will simply reject this, you know, and I'm not even speaking about passing regulatory approvals and so on. I'm even speaking from a pure, you know, consumer sentiment and how would it be adopted? So I think that's kind of the big challenge. And in order to do this, we believe that, you know, you need to be able to prove that the system is safer than a very good human driver. And that is a very high bar, you know, if you think about statistics. So I think that's kind of where where the complexity lies. And there has been, there have been multiple attempts in the industry by different companies, very capable companies of kind of cracking into this. I think that there is definitely new tools today. There are definitely new tools. Technology is moving very fast. And we are at a position of being very confident in our chances in our plans to launch this on time, as I said in two years, and to kind of unlock this body for consumers. Yeah, no, I think this is this is what makes us one of the most interesting areas in the whole driving automation space is that, you know, we are, we see sort of, you know, with L4, right, with these robot taxis, you know, we see companies doing this where if you constrain the operation to a very specific area that allows you to build up that mathematical certainty that you have validated its its safe performance within that area. And there's the constraining that that operating domain is so important to that. And and then the flip side, right, is that cars are like general purpose mobility devices, right, they kind of have to be useful anywhere you go, everywhere you go. And so and so it's that balance. So, you know, I know that that mobile, I wanted to ask anything you've worked on. It's been great to fall over the years is is the R&M, the the road experience management, this distributed mapping system. I assume that this is one of the pieces that is really helpful for you all in terms of identifying sort of, you know, giving us this balance, right, between as many domains as possible to get us close as much automation to as many of the places where people are going to take their cars. While at the same time constraining it enough that you can actually, you know, you're not, you're not trying to prove safety in an unlimited domain, which is statistically kind of a, too much much harder thing to prove. Talk about the role of mapping and this unique mapping tool that you have and in trying to solve this problem. Yeah. I think that our R&M technology is a very strong and important enabler for scalability. And scalability has two facets. It's the geographic scalability and the economic scalability. An equally important element of having a meaningful product is how much does it cost. And it's another very, very strong constraint on the solution, because again, solving autonomous driving, but in a, in a $200,000 system cost will really minimize its impact on society. So there is a very strict challenge or very strict bar, sorry, that you need to, to keep on the system cost and the efficiency of the design. So R&M is, you know, maybe the way we think of R&M is not as a pure high definition map, like traditionally being referred to in the industry. I think a better way to understand this intuitively is thinking about R&M as a memory for a human driver. So, you know, you and I, when we're driving our daily commute, we drive much safer, much more comfortably. You can always almost anticipate what's coming before you see it, because you know it from experience. And having this pre, like pre-existing understanding of the road really helps you and serve you when you're driving. Compare this experience to driving in, I don't know, Mumbai for the first time, you know, I've actually done that. It's, it's terrifying. Yeah. Very significant difference in performance of how you drive, not just in comfort, you know, or even meeting all the driving rules, but of course in safety. So we want to maintain this equals standard, highest standard of driving performance everywhere. So the way we do this is we kind of create this, this global memory database that's millions of mobile I cars, when I say mobile I cars, cars are referred to cars that deploy mobile I products. And these are the standard driver assist products. It's a very, very, very low end product, but still we use this to upload data to build this memory database globally. And we have today more than 8 million cars globally from multiple car makers all over the world. And we built this database that is continuously being updated and it's very fresh. And it includes every insight we can have on the road. So it's not just about the position of things. It's also about meaning. It's also, you know, you need to understand notions of who gives who right of way, which lane has right of way, which lane gives right of way. Driving rules, the average driving speed versus the legal driving speed, where pedestrians are crossing, even if there is no crosswalk. So many different insights. So this is obviously a very strong boost to the AI machine that makes decisions in the car, because you have this as an input of what millions of drivers experienced before you are traversing a certain road. Yeah. And I think that this really helps give some texture to help sort of think beyond just purely about training models, right? That there's this sort of this ongoing conversation between the data that's coming off cars, right? And the systems that are going out and navigating the world. And of course, now, you know, this is reflective of this broader paradigm of software to find vehicles that we're moving towards, where now the data and the change kind of moves both directions, right? And I'm kind of curious, you know, you mentioned cost. Obviously, there's talk about, you know, subscriptions and obviously we're getting a little bit into how your OEM partners choose to take your technology and productize it, of course. But I'm curious, you know, is our, you know, in these conversations as these products move towards market, is it sort of a situation where, you know, a product is going to have all of its features up front? Or are OEMs looking to deploy these technologies in ways that more sort of evolves over time? Maybe, you know, eyes off starts on certain roads and over time, you know, as the system evolves, you know, in that exchange of data brings more levels of of capability and validation that then those roads were able to use that, you know, get your time back then sort of starts to expand over time. Yeah, I think it's a very good question. And it's pretty clear that there is no right obvious answer given the different experimentation that OEMs are doing. And I think that OEMs are trying to kind of, you know, dip their toes in different paths and see what, you know, what has attractions with consumers and what doesn't have traction. What I think is clear is consumers will want some level of certainty about what they're buying. And having like an open check statements at day one of selling, you know, selling the car and saying one day it might be the sales driving car, just wait, is it's a very tricky, you know, setting pitch for most OEMs. That will require us to give the certainties about, you know, how much time what will be the criteria having an objective measure that, you know, potentially OEMs can also provide to their customers and say, when you buy the car, there's this amount of time that needs to pass and these are the things that we're doing. And this is how you will, as a consumer, will know if you're going to get the self driving car or not. And then you pay X or we, you know, pay Y, whatever. So I think that is a very important component. And still, I think that OEMs will prefer a gradual launch of these highest and are like most advanced features starting by, you know, IZON and then gradually expanding the, you know, the performance envelope that will allow the drivers to take their eyes off. But that has to have a certain boundary to it. It cannot be unbounded. Yeah. No, and as you say, I think everyone is still figuring out, right, how to make these features cost-effective, affordable, and what is the right way to package them, you know, that's really going to drive the uptake and get those benefits into people's hands. You know, the experimentation is happening there where I think maybe there's one more settled certainty, which is really important foundation of how you think about cost and product, which is the hardware, right? And of course, there's been there too, a lot of conversation, a lot of debate. But also, I think over time, you know, a lot more sort of certainty and consensus building around it. And one of the things, of course, we noticed with with mobile IIS, who shift in the hardware strategy a bit, in-house development of frequency modulated, a concept wave light R has been ended. You're moving more towards, it looks like imaging radar is sort of a big focus on the hardware side. Talk to me a little bit about how that strategy is shifting a little bit at mobile. Yeah. So, when we, as a outlined the product portfolio, our strategy is to develop the core components in the sales driving system for these product portfolio. So, that includes the the compute hardware, the ECUs themselves, that includes the silicon, it obviously includes the software and the AI components. And then also, the critical sensors that are enabling the IISOF node driver driving applications. So, the reason why we're doing this is because we believe that OEMs will appreciate a technology partner that can provide the core components. And you have one stop shop, as opposed to having kind of an integration nightmare where you need to go to five different parties to get specific parts. And then the OEMs assumes all the risk and need to be responsible for this building disposal. And we know this also from experience. Now, referring specifically to your question. So, we did have a research program for FMCW LiDARs and we had a few years of this research. The reason why we have decided to end this is primarily because we see less value for this technology in our future. And that was a factor of the confidence we have in our imaging radar and also the confidence we have in our next gen AI technology. And we basically think that we can minimize system costs. We can rely on less expensive parts. Not just expensive is important, not just because of the dollar figure, but also the complexity of integrating very high-end optical sensors. It has additional costs beyond just the price for the product. And a simple system is better. Having a simple system is always better than a complicated system. And now we have a lot more confidence that we can maintain the same performance by significantly simplifying. And is it one of the challenges with some of these cutting-edge sensor technologies? Putting them in the... Again, when you have a robotaxe fleet that you as the operator own, things like sensor calibration, you make sure you're always on top of that. But private cars, I mean, you know, I have friends who've blown up their engines because they didn't put oil in. You know, you can't have that... Is that sort of a factor here with some of these more sophisticated sensor modalities? Yeah. Well, I think LiDAR is... It's an inherent challenge with LiDARs. Is it requires very delicate care. And it's sensitive to influences, to external influences, you know, like environmental conditions, if it gets dirty, if it has, you know, some mud or dirt, if it had some rain drops, it needs to be properly maintained to be effective and reliable. Radar is a much more robust sensor. It's much less affected by these external factors. The problem with radars, traditionally, was not their robustness or kind of resilience to these conditions. It was mostly about their resolution and their especially angular resolution, specifically for radars, which meant that you cannot really use radars as a standalone sensor for autonomous driving because, you know, it doesn't give you enough fidelity, enough understanding of the environment. Even in simple use cases, like if you have a pedestrian standing next to a truck, you will not be able to differentiate the pedestrian from the truck with traditional radars. And that is obviously an important notion. So our imaging radars, and that's one of the reasons why we're kind of going very strongly with investing into this, is really unlocking this. So it uses AI and it uses, you know, very, very strong like radar technology and you practically has the same resolution as a camera. But you have it with a different modality that had different failures so that you can have this redundancy effect that we're looking for for safety. Yeah, and I think it's very easy to to kind of lump all these, you know, one modality altogether. And so it's all just radar, but the difference between, you know, a very cheap radar that's used for, say, adaptive cruise control and this new sophisticated imaging radar is so huge in terms of that performance, which then of course, unlocks, as you say, all of this ability to take AI techniques that were before only really usable with a camera. Now as that radar technology gets more sophisticated, you can start to apply them as well. 100%. Yeah. We're running out of time here. So I'd like to ask you to just sort of wrap up by telling us a little bit, where do you see this market going? I mean, how, so it sounds like, you know, another good year or so before we start to really see these eyes off system hit the market. Give us a sense of how big that market could get how fast it could start to grow. Is this something that will be just a few cars and very, very premium for a number of years? Is this something we're going to see sort of radically take off? Like how do you see the the market for for eyes off, particularly involving? Yeah, well, of course, this is a very tricky question that I can make myself a fool of by trying to answer, but I'll give it my best attempt by not trying to be a prophet or try to predict the future too much. But I think if you look at this in broad terms, today, with all of the advancement in the industry, events in AI, and announcements about progress towards autonomous driving from many big companies that have a lot of resources. Still today, only a very small fraction of the models driven by humanity are economists. It's a fraction of a fraction of a fraction. And I think the interesting question is, will we ever get to, you know, 10%, 20%, 20%, 50%, and then 100% of all miles driven that are autonomous? So I think that the most important realization, in my view, at least my personal view from the past year, is that the answer to the if question is yes. And maybe some skeptics could argue the past that, you know, there is no evidence that it's even solvable. And it's just as far out-treme. But I think that the technology engineering aspects and also like the social climate today gives us a lot more confidence that it's coming. And of course, now it's a question of scale. It's a question of availability, which, you know, areas can be supported in which conditions it can be supported, and how long will it take to scale in the industry that has, you know, very kind of long cycles traditionally. So I don't know if it will take us three years, five years, three months, 30 years to scale from 0%, almost 0% to 50%. But I do think it's coming, and I think it's coming in a shorter amount of time that people anticipate. That's my personal, you know, assumption. And we think that eventually there might not be just one company that is kind of responsible for this massive shift, but there won't be 20. Because, you know, combining the kind of the complexity, the technological complexity, but also the necessity of a scalable solution, both economically scalable and also geographically scalable, means that realistically, maybe a couple two or three or four players will be the enablers for this revolution in the West, and we have a lot of confidence at mobile that will be one of them. So we'll need to play it out and see how it goes. Absolutely. Well, this has been an amazing conversation, you know, I think over the last few years, there's been sort of obviously we had, you know, so much hype and excitement in the space, and we had a couple of sort of down years where people got kind of down about the fact that it wasn't all happening overnight as, you know, sort of some people hope. But to me, I feel like this moment that we're in that you're describing right now is kind of almost more exciting in a way, because you see it starting to become real. And these conversations, you know, we're getting, you know, more into the nitty gritty of how this stuff is actually happening, and it's really starting to roll out and become real. And it's harder, you know, but it's more interesting, I think, as a result. And I think that, you know, nothing worth doing is ever easy. And it's just been certainly fascinating to watch this journey. And I really looking forward to spending some time with you in Hollywood at the summit and discussing it some more. It's a really exciting time. Thank you very much. Thank you so much. And thank you listeners. So, listen to the right-of-eye podcast.",
    "rearview_prompt_2": "Provide a brief headline (bolded text, not an actual headline) and a one-sentence summary. adress the fact that nimrod was in a podcast and what he talked about in general. Keep the response extremely concise\u2014no more than 4 sentences total.\n\n",
    "rearview_urls_3": "",
    "rearview_notes_3": "Here is the story:\n\"\"\"\nRomance, lies, and ChatGPT: The scandal shaking Tel Aviv\u2019s startup scene\nPromai sues former CEO over bogus contracts with global giants and a web of personal deceit. \nTomer Ganon\n14:42, 21.04.25\nTAGS:\nPromai\nLawsuit\nCourt\n\n\"The CEO posed as a senior officer in the Air Force and forged, cheated, lied, and defrauded the company\" \u2014 this is what the startup Promai alleges in a 10 million shekel (approximately $2.7M) lawsuit filed Sunday with the Tel Aviv District Court.\n\u201cI forged the contract\u201d: Promai CEO allegedly confesses in sting to faking Boeing deal with ChatGPT\nAccording to the company, an investigation by the Wizman-Yaar business investigation firm revealed that its recently departed CEO, Erez Ben Eshay \u2014 who was also the romantic partner of the company\u2019s founder and largest shareholder \u2014 allegedly forged documents, including using ChatGPT, to fabricate a contract for product development with Boeing.\n\u05d8\u05d9\u05d9\u05e1 \u05de\u05d8\u05d5\u05e1 \u05e0\u05d5\u05e1\u05e2\u05d9\u05dd \u05d4\u05e7\u05d1\u05e8\u05e0\u05d9\u05d8 \u05e1\u05d5\u05d3\u05d5\u05ea \u05d4\u05d8\u05d9\u05e1\u05d4\nA pilot. (Photo: Shutterstock)\nPromai, which employed about 40 people and is based in Tel Aviv, has developed a technological solution intended to streamline the transfer of vital information to production lines and reduce operational malfunctions. The company was founded in 2022 by Dr. Dina Olga Goren-Bar, an expert in artificial intelligence, and has raised $7 million from private investors.\nThe Promai website and any LinkedIn presence have been deleted. \nIntel braces for massive layoffs, with Israeli operations facing uncertainty | CTech\nCTech\nInside Intel\u2019s biggest-ever layoff: a blueprint for a wounded giant | CTech\nCTech\nAccording to the lawsuit, Dr. Goren later met Ben Eshay, who presented himself as a test pilot and a reserve officer with the rank of lieutenant colonel in the Israeli Air Force. \u201cThe defendant fraudulently gained Dr. Goren\u2019s trust, leading her to maintain a personal relationship with him,\u201d the lawsuit states. \u201cIt has now become clear that the defendant is married and living with another woman, and that the stories he told Dr. Goren about being away for military or operational duties were fabricated.\u201d\nRelated articles:\nDeel \u2018spy\u2019 avoids punishment as Irish court targets company\u2019s CEO and legal team\nHydrogen startup Electriq Global collapses under nearly $30M in debt, despite raising $25M\nLawyer\u2019s AI reliance results in fictitious court citations in Supreme Court petition\nThe suit further alleges: \u201cBased on the defendant\u2019s false representations, he received 12% of the company\u2019s shares from Dr. Goren at the time of its founding and was appointed CEO.\u201d\nThe company claims that over the past year it had been manufacturing products it believed were ordered by Medtronic and Boeing. These were purported to be prestigious contracts with global companies, whose execution would have conferred substantial revenue and reputational benefits on Promai.\n\u201cA few days before this lawsuit was filed,\u201d the complaint continues, \u201cit became clear that the defendant had falsified all the contract documentation related to Medtronic and Boeing, as well as other key contract documents of the company. This means the company spent about a year and a half manufacturing products that were never ordered \u2014 not by Medtronic, not by Boeing, and not by anyone else. Approximately 20 million shekels were spent under false pretenses.\u201d\nThe lawsuit claims that the damage to Promai is \u201cenormous.\u201d \u201cThe company had a product in its early stages of development, and due to the defendant\u2019s fraudulent actions, it invested nearly all of its resources in preparing products that were never ordered. This came at the expense of developing the product for real, potential customers.\u201d\nAttorneys Ariel Shmul and Avital Kidron, who represent Ben Eshay, responded:\n\u201cOur client denies all allegations against him. These claims are entirely baseless and completely fabricated. Our client acted lawfully and ethically in his capacity as CEO. He has suffered significant personal and financial harm due to the conduct of certain individuals within the company. The use of his name in this affair is a mistake, and he is not responsible for the situation. At most, this appears to be a commercial dispute among other parties \u2014 not one involving our client.\u201d\n\"\"\"",
    "rearview_prompt_3": "Provide a brief headline (bolded text, not an actual headline) and a one-sentence summary. Keep the response extremely concise\u2014no more than 3 sentences total. address the fact that this story is extremely unique and \u05d4\u05d6\u05d5\u05d9"
}